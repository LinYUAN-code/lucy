function e(e,t){return t.map((e=>e.replaceAll(/\s/g,""))).map((t=>{const n=t.split(/(=>)|(->)/).filter((e=>"=>"!==e&&"->"!==e&&e)),r=n[1].split("|").filter((e=>e&&"|"!==e)).map((t=>e.splitDerivation(t)));return{nonTerminal:n[0],derivations:r}}))}function t(e){switch(e){case"+":case"*":case"(":case")":return`\\${e}`;default:return e}}const n="ε",r="$";var i;!function(e){e[e.Normal=0]="Normal",e[e.Warnning=1]="Warnning",e[e.Error=2]="Error",e[e.None=3]="None"}(i||(i={}));let o=i.Normal;o=i.Error;var s=new class{logLevel;logChannel;constructor(e=i.Normal,t=console){this.logLevel=e,this.logChannel=t}log(...e){this.logLevel<=i.Normal&&this.logChannel.log("[normal]",...e)}warn(...e){this.logLevel<=i.Warnning&&this.logChannel.warn("[warn]",...e)}error(...e){this.logLevel<=i.Error&&this.logChannel.error("[error]",...e)}logTo(e){this.logChannel=e}}(o);function l(t,r){s.log("[generateFirstSet start]");const i=e(t,r);s.log("[grammers after transferString2Grammers]",i);const o=new Array(...i.map((e=>({tocken:e.nonTerminal,terminals:new Set})))),l=new Map;i.forEach((e=>{l.set(e.nonTerminal,e.derivations)})),o.push(...t.terminals.map((e=>({tocken:e[0],terminals:new Set([e[0]]),isTerminal:!0})))),o.forEach((e=>{if(!e.isTerminal)for(let t of l.get(e.tocken))1!==t.length||t[0]!==n||e.terminals.has(n)||e.terminals.add(n)}));const a=new Map;for(let e of o)a.set(e.tocken,e);for(;;){let e=!1;if(o.forEach((r=>{if(!r.isTerminal)for(let i of l.get(r.tocken))for(let o=0;o<i.length;o++){const l=i[o];if(t.isTerminal(l)){if(r.terminals.has(l)||(s.log(l),e=!0,r.terminals.add(l)),l!==n)break}else{const t=a.get(l);if(t.terminals.forEach((t=>{t!==n&&(r.terminals.has(t)||(e=!0,r.terminals.add(t)))})),!t.terminals.has(n))break}o===i.length-1&&r.terminals.add(n)}})),!e)break}return o.filter((e=>!e.isTerminal)).sort(((e,t)=>e.tocken<t.tocken?-1:1)).map((e=>(e.terminals=new Set(Array.from(e.terminals).sort(((e,t)=>e<t?-1:1))),e)))}function a(e,t,r){const i=new Set;for(let o=0;o<t.length;o++){const s=t[o];if(e.isTerminal(s)){if(s!==n){i.add(s);break}}else if(r.get(s)?.terminals.forEach((e=>{i.add(e)})),!r.get(s).terminals.has(n))break;o===t.length-1&&i.add(n)}return{tocken:t.join(""),terminals:i}}class c{nonTerminals;terminals;currentLine=0;currentColumn=0;source="";constructor(e,t){this.nonTerminals=[...t],this.terminals=[...e]}setSource(e){this.source=e,this.currentLine=0,this.currentColumn=0}remainString(){return this.source.slice(this.currentColumn)}next(){if(this.currentColumn>=this.source.length)return{tocken:r,origin:r};for(let e of this.terminals){const t=this.source.slice(this.currentColumn).match(e[1]);if(t)return{tocken:e[0],origin:t[0]}}throw new Error(`[lexer next]: match next Terminal error \n sourecInput: ${this.source}\n remainString: ${this.source.slice(this.currentColumn)}`)}pop(){try{const e=this.next();return e.tocken!==r&&(this.currentColumn+=e.origin.length),e}catch(e){throw e}}nextNotEmptyTerminal(){for(;;){const e=this.next();if("whiteSpace"!==e.tocken)return e;this.currentColumn+=e.origin.length}}nextNotEmpty(e){const t=this.currentColumn;for(let t=0;t<e-1;t++)this.popNotEmptyTerminal();const n=this.nextNotEmptyTerminal();return this.currentColumn=t,n}popNotEmptyTerminal(){const e=this.nextNotEmptyTerminal();return e.tocken!==r&&(this.currentColumn+=e.origin.length),e}isTerminal(e){let t=!0;return this.nonTerminals.some((n=>n===e&&(t=!1,!0))),t}splitDerivation(e){const n=[];let r=0;const i=e;for(;e.length;){for(let t of this.nonTerminals){const r=e.match(new RegExp("^"+t));if(r){n.push(t),e=e.slice(r[0].length);break}}for(let r of this.terminals){const i=e.match(new RegExp("^"+t(r[0])));if(i){n.push(r[0]),e=e.slice(i[0].length);break}}if(r++,r>5e4)throw new Error(`[splitDerivation] error: excute over MAX_EXCUTE str: ${i}  remaining str: ${e} `)}return n}getNewNonTerminal(e){let t=e;for(;;)if(t+="'",-1===this.nonTerminals.indexOf(t))return this.nonTerminals.unshift(t),t}}function m(t,r,i,o){const l=e(t,r),c=[],m=new Map;t.nonTerminals.forEach((e=>{const t={nonTerminal:e,terminal2Derivation:new Map};m.set(e,t),c.push(t)}));const f=new Map,h=new Map;for(let e of o)h.set(e.tocken,e);for(let e of i)f.set(e.tocken,e);return l.forEach((e=>{for(let r of e.derivations){const i=a(t,r,f),o=m.get(e.nonTerminal);s.log(i);for(let t of i.terminals){if(t===n)continue;let i=o?.terminal2Derivation.get(t);i||(i={nonTerminal:e.nonTerminal,derivations:[]},o?.terminal2Derivation.set(t,i)),i.derivations.push(r)}if(i.terminals.has(n))for(let t of h.get(e.nonTerminal).terminals){let n=o?.terminal2Derivation.get(t);n||(n={nonTerminal:e.nonTerminal,derivations:[]},o?.terminal2Derivation.set(t,n)),n.derivations.push(r)}}})),c}function f(e,t){for(let n of e.terminals){const e=n[0];t.forEach((t=>{const n=t.terminal2Derivation.get(e);if(n&&n.derivations.length>1)return!1}))}return!0}class h{lexer;textGrammers;constructor(e,t,n){this.lexer=new c(e,t),this.textGrammers=n}getFirstSet(){return l(this.lexer,this.textGrammers)}getFollowSet(t){return t||(t=this.getFirstSet()),function(t,i,o){s.log("[generateFllowSet start]"),o=o?Array.from(o):l(t,i);const a=e(t,i);s.log("[grammers after transferString2Grammers]",a);const c=new Array(...a.map((e=>({tocken:e.nonTerminal,terminals:new Set([r])})))),m=new Map;a.forEach((e=>{m.set(e.nonTerminal,e.derivations)})),c.push(...t.terminals.map((e=>({tocken:e[0],terminals:new Set([r]),isTerminal:!0}))));const f=new Map;for(let e of c)f.set(e.tocken,e);o.push(...t.terminals.map((e=>({tocken:e[0],terminals:new Set([e[0]]),isTerminal:!0}))));const h=new Map;for(let e of o)h.set(e.tocken,e);for(;;){let e=!1;if(a.forEach((t=>{for(let r of t.derivations)for(let t=r.length-2;t>=0;t--){const i=f.get(r[t]);for(let o=t+1;o<r.length;o++){const t=h.get(r[o]).terminals;for(let r of t)r!==n&&(i?.terminals.has(r)||(e=!0,i?.terminals.add(r)));if(!t.has(n))break}}})),a.forEach((t=>{const r=f.get(t.nonTerminal);for(let i of t.derivations)for(let t=i.length-1;t>=0;t--){const o=i[t],s=f.get(o);for(let t of r.terminals)t!==n&&(s?.terminals.has(t)||(e=!0,s?.terminals.add(t)));if(!h.get(o).terminals.has(n))break}})),!e)break}return c.filter((e=>!e.isTerminal)).sort(((e,t)=>e.tocken<t.tocken?-1:1)).map((e=>(e.terminals=new Set(Array.from(e.terminals).sort(((e,t)=>e<t?-1:1))),e)))}(this.lexer,this.textGrammers,t)}getPredictTable(e,t){return e||(e=this.getFirstSet()),t||(t=this.getFollowSet(e)),m(this.lexer,this.textGrammers,e,t)}getPredictProcess(e,t,i){return i||(i=m(this.lexer,this.textGrammers,this.getFirstSet(),this.getFollowSet())),function(e,t,i,o){let l=i.replaceAll(/\s/g,"");const a=[];let c={parseStack:[r,o],remainingInput:i,parseAction:""};e.setSource(l);const m=new Map;for(t.forEach((e=>{m.set(e.nonTerminal,e)}));;){const t=c.parseStack[c.parseStack.length-1];if(e.isTerminal(t)){const n=e.next();if(t!==n.tocken)throw new Error(`[predict error] terminal match error tocken: ${t} stack: ${c.parseStack} remainingInput: ${e.remainString()}`);if(c.parseAction=`match ${n.tocken} ${n.origin}`,a.push(c),c=JSON.parse(JSON.stringify(c)),e.pop(),c.parseAction="",c.remainingInput=e.remainString(),c.parseStack.pop(),0===c.parseStack.length)break;continue}const r=e.next(),i=m.get(t).terminal2Derivation.get(r.tocken);if(1!==i.derivations.length)throw new Error(`[predict error] parse input fail \n terminal: ${r} \n  remainingInput: ${e.remainString()} \n grammer: ${i} `);c.parseAction=`Predict ${i.nonTerminal} => ${i.derivations[0].join(" ")}`,s.log("[predict State]",c),a.push(c),c=JSON.parse(JSON.stringify(c)),c.parseStack.pop(),c.parseStack.push(...i.derivations[0].filter((e=>e!==n)).reverse()),c.parseAction="",c.remainingInput=e.remainString()}return a}(this.lexer,i,e,t)}checkPredickTableIsValid(e){return f(this.lexer,e)}checkIsLL0(){return f(this.lexer,this.getPredictTable())}getFirstSetProgressive(){return function*(t,r){yield["1. 如果X式一个终结符号，那么FIRST(X) = X ","2. 如果 X => ε 是一个产生式，那么将e加人到 FIRST（X)中。","3. A => B0B1B2B3\n            i = 0\n            FIRST(Bi) - EmptyCharacter 加入到 FIRST(A)中\n            如果FIRST(B1)不含有EmptyCharacter退出循环\n            若B0 - B3均含有EmptyCharacter 将EmptyCharacter加入到FIRST(A)中\n        ","4. 去除所有终结符号的表项"],s.log("[generateFirstSet start]");const i=e(t,r);s.log("[grammers after transferString2Grammers]",i);const o=new Array(...i.map((e=>({tocken:e.nonTerminal,terminals:new Set})))),l=new Map;i.forEach((e=>{l.set(e.nonTerminal,e.derivations)})),o.push(...t.terminals.map((e=>({tocken:e[0],terminals:new Set([e[0]]),isTerminal:!0})))),yield{ruleIndex:0,result:o},o.forEach((e=>{if(!e.isTerminal)for(let t of l.get(e.tocken))1!==t.length||t[0]!==n||e.terminals.has(n)||e.terminals.add(n)})),yield{ruleIndex:1,result:o};const a=new Map;for(let e of o)a.set(e.tocken,e);for(;;){let e=!1;if(o.forEach((r=>{if(!r.isTerminal)for(let i of l.get(r.tocken))for(let o=0;o<i.length;o++){const l=i[o];if(t.isTerminal(l)){if(r.terminals.has(l)||(s.log(l),e=!0,r.terminals.add(l)),l!==n)break}else{const t=a.get(l);if(t.terminals.forEach((t=>{t!==n&&(r.terminals.has(t)||(e=!0,r.terminals.add(t)))})),!t.terminals.has(n))break}o===i.length-1&&r.terminals.add(n)}})),!e)break;yield{ruleIndex:2,result:o}}yield{ruleIndex:3,result:o.filter((e=>!e.isTerminal)).sort(((e,t)=>e.tocken<t.tocken?-1:1)).map((e=>(e.terminals=new Set(Array.from(e.terminals).sort(((e,t)=>e<t?-1:1))),e)))}}(this.lexer,this.textGrammers)}getFollowSetProgressive(t){return t||(t=this.getFirstSet()),function*(t,i,o){yield["1. 将$放到FOLLOW(S)中","2. 如果存在一个产生式A => aBb ， 那么FIRST(b) 中除ε 之外的所有符号都在FOLLOW(B)中。attention: A => aBCd 那么把first(Cd)加入到Follow(B)中去","3.如果存在一个产生式 A => aB ， 或存在产生式 A => aBb 且FIRST(b) 包含 ε ，那么FOLLOW(A)中的所有符号都在FOLLOW(B)中。","4. 去除所有终结符号的表项"],s.log("[generateFllowSet start]"),o=o?Array.from(o):l(t,i);const a=e(t,i);s.log("[grammers after transferString2Grammers]",a);const c=new Array(...a.map((e=>({tocken:e.nonTerminal,terminals:new Set([r])})))),m=new Map;a.forEach((e=>{m.set(e.nonTerminal,e.derivations)})),c.push(...t.terminals.map((e=>({tocken:e[0],terminals:new Set([r]),isTerminal:!0})))),yield{ruleIndex:0,result:c};const f=new Map;for(let e of c)f.set(e.tocken,e);o.push(...t.terminals.map((e=>({tocken:e[0],terminals:new Set([e[0]]),isTerminal:!0}))));const h=new Map;for(let e of o)h.set(e.tocken,e);for(;;){let e=!1;if(a.forEach((t=>{for(let r of t.derivations)for(let t=r.length-2;t>=0;t--){const i=f.get(r[t]);for(let o=t+1;o<r.length;o++){const t=h.get(r[o]).terminals;for(let r of t)r!==n&&(i?.terminals.has(r)||(e=!0,i?.terminals.add(r)));if(!t.has(n))break}}})),e&&(yield{ruleIndex:1,result:c},e=!1),a.forEach((t=>{const r=f.get(t.nonTerminal);for(let i of t.derivations)for(let t=i.length-1;t>=0;t--){const o=i[t],s=f.get(o);for(let t of r.terminals)t!==n&&(s?.terminals.has(t)||(e=!0,s?.terminals.add(t)));if(!h.get(o).terminals.has(n))break}})),e&&(yield{ruleIndex:2,result:c}),!e)break}yield{ruleIndex:3,result:c.filter((e=>!e.isTerminal)).sort(((e,t)=>e.tocken<t.tocken?-1:1)).map((e=>(e.terminals=new Set(Array.from(e.terminals).sort(((e,t)=>e<t?-1:1))),e)))}}(this.lexer,this.textGrammers,t)}getPredictTableProgressive(t,r){return t||(t=this.getFirstSet()),r||(r=this.getFollowSet(t)),function*(t,r,i,o){yield["1. 对 First(u) 中的所有终结符 a （不含 ε ），置 M[A, a] = A -> u","2. 若 First(u) 含 ε ，则对 Follow(A) 中的所有符号 a （可含 $ ），置 M[A, a] = A -> u"];const l=e(t,r),c=[],m=new Map;t.nonTerminals.forEach((e=>{const t={nonTerminal:e,terminal2Derivation:new Map};m.set(e,t),c.push(t)}));const f=new Map,h=new Map;for(let e of o)h.set(e.tocken,e);for(let e of i)f.set(e.tocken,e);for(let e of l)for(let r of e.derivations){const i=a(t,r,f),o=m.get(e.nonTerminal);s.log(i);for(let t of i.terminals){if(t===n)continue;let i=o?.terminal2Derivation.get(t);i||(i={nonTerminal:e.nonTerminal,derivations:[]},o?.terminal2Derivation.set(t,i)),i.derivations.push(r),yield{ruleIndex:0,result:c}}if(i.terminals.has(n))for(let t of h.get(e.nonTerminal).terminals){let n=o?.terminal2Derivation.get(t);n||(n={nonTerminal:e.nonTerminal,derivations:[]},o?.terminal2Derivation.set(t,n)),n.derivations.push(r),yield{ruleIndex:1,result:c}}}}(this.lexer,this.textGrammers,t,r)}}const g=/^[A-Z]'*/,p=/[a-z|\u0391-\u03C9]/;function u(e){const t=new Set,n=new Set;return e.forEach((e=>{const r=e.replaceAll(/\s/g,"").split(/(=>)|(->)/).filter((e=>"=>"!==e&&"->"!==e&&e)),i=r[0];t.add(i),r[1].split("|").filter((e=>e&&"|"!==e)).forEach((e=>{for(;e.length;){let r=null;if(r=e.match(g),r)t.add(r[0]),e=e.slice(r[0].length);else{if(r=e.match(p),!r)throw new Error(`[getTockFromSimpleGrammers error] cant recognize the character remaining: ${e}`);n.add(JSON.stringify([r[0],"^"+r[0]])),e=e.slice(r[0].length)}}}))})),{nonTerminals:Array.from(t).sort(((e,t)=>t.length-e.length)),terminals:Array.from(n).map((e=>{const t=JSON.parse(e);return t[1]=new RegExp(t[1]),t}))}}function d(e){let t=new Map;for(let n of e){n=n.replaceAll(/\s/g,"");const e=n.split(/(=>)|(->)/).filter((e=>"=>"!==e&&"->"!==e&&e)),r=e[0],i=e[1];if(t.has(r))return!0;t.set(r,[i])}return!1}function T(e){let t=new Map;const n=[];e.forEach((e=>{const n=(e=e.replaceAll(/\s/g,"")).split(/(=>)|(->)/).filter((e=>"=>"!==e&&"->"!==e&&e)),r=n[0],i=n[1];if(t.has(r)){const e=t.get(r);e?.push(i),t.set(r,e)}else t.set(r,[i])}));for(let e of t.keys()){const r=[...new Set(t.get(e))];n.push(`${e} => ${r.join("|")}`.split("|").join(" | "))}return s.log(n),n}function w(e,t,n){let r=e;if(!t||!n){const r=u(e);t=r.nonTerminals,n=r.terminals}let i=new c(n,t);for(let e of r){e=e.replaceAll(/\s/g,"");const t=e.split(/(=>)|(->)/).filter((e=>"=>"!==e&&"->"!==e&&e))[1].split("|").filter((e=>e)).map((e=>(s.log("[debug]",r),i.splitDerivation(e)))),n=new Map;t.forEach((e=>{let t=n.get(e[0]);t?t.push(e.slice(1)):t=[e.slice(1)],n.set(e[0],t)}));for(let e of n.keys())if(1!==n.get(e)?.length)return!0}return!1}function k(e,t,n){let r=e;if(!t||!n){const r=u(e);t=r.nonTerminals,n=r.terminals}let i=new c(n,t);for(;;){let e=[];const t=r.map((t=>{const n=(t=t.replaceAll(/\s/g,"")).split(/(=>)|(->)/).filter((e=>"=>"!==e&&"->"!==e&&e)),o=n[0],l=n[1].split("|").filter((e=>e)).map((e=>(s.log("[debug]",r),i.splitDerivation(e)))),a=[],c=new Map;l.forEach((e=>{let t=c.get(e[0]);t?t.push(e.slice(1)):t=[e.slice(1)],c.set(e[0],t)}));for(let t of c.keys()){if(1===c.get(t)?.length){a.push(t+c.get(t)[0].join(""));continue}const n=c.get(t),r=i.getNewNonTerminal(o);a.push(t+r),e.push(r+" => "+n?.map((e=>e.join(""))).join(" | "))}return o+" => "+a.join(" | ")}));s.log("[pre]",t,e);const n=[...t,...e];if(s.log("[com]",r,n),r.length===n.length)break;r=n}return r}function S(e,t,n){if(!t||!n){const r=u(e);t=r.nonTerminals,n=r.terminals}s.log("[nonTerminals]",t),s.log("[terminals]",n);let r=new c(n,t);const i=new Map;for(let t of e){t=t.replaceAll(/\s/g,"");const e=t.split(/(=>)|(->)/).filter((e=>"=>"!==e&&"->"!==e&&e)),n=e[0],o=e[1].split("|").filter((e=>e)).map((e=>r.splitDerivation(e)));i.set(n,o)}s.log("[nonTerminals2DerivationMap]",i);for(let e=0;e<t.length;e++){const n=i.get(t[e]);for(let r=n.length-1;r>=0;r--){if(n[r][0]===t[e])return!0}}return!1}function v(e,t,r){const i=[];if(!t||!r){const n=u(e);t=n.nonTerminals,r=n.terminals}s.log("[nonTerminals]",t),s.log("[terminals]",r);let o=new c(r,t);const l=new Map;for(let t of e){t=t.replaceAll(/\s/g,"");const e=t.split(/(=>)|(->)/).filter((e=>"=>"!==e&&"->"!==e&&e)),n=e[0],r=e[1].split("|").filter((e=>e)).map((e=>o.splitDerivation(e)));l.set(n,r)}s.log("[nonTerminals2DerivationMap]",l);for(let e=0;e<t.length;e++){const r=l.get(t[e]);for(let n=0;n<e;n++){const e=l.get(t[n]);for(let i=r.length-1;i>=0;i--){const o=r[i];if(o[0]===t[n]){s.log(o,t[n]);for(let t of e)s.log("[-]",t),r?.push([...t,...o.slice(1)]);r?.splice(i,1)}}}const i=[];for(let n=r.length-1;n>=0;n--){r[n][0]===t[e]&&i.push(n)}if(i.length){const s=o.getNewNonTerminal(t[e]),a=[],c=[];for(let e=r.length-1;e>=0;e--)-1===i.indexOf(e)&&a.push([...r[e][0]===n?r[e].slice(1):r[e],s]);for(let e of i)c.push([...r[e].slice(1),s]);c.push([n]),l.set(t[e],[...a,...i.length?[]:r]),l.set(s,c)}s.log("[nonTerminals2DerivationMap in process]",l,r)}for(let e of l.keys()){const t=l.get(e).map((e=>e.join(""))).join(" | ");i.push(`${e} => ${t}`)}return i}export{h as LL1Parser,c as Lexer,S as checkNeedClearRightRecursion,w as checkNeedliftUpCommonTocken,d as checkNeedunionGrammers,v as clearRightRecursion,u as getTockFromSimpleGrammers,k as liftUpCommonTocken,T as unionGrammers};
